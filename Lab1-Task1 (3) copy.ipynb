{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57b00152",
   "metadata": {
    "id": "57b00152"
   },
   "source": [
    "# Lab 1 Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc389ae1",
   "metadata": {
    "id": "bc389ae1"
   },
   "source": [
    "## 1. Implement the following layers as Python functions (both forward and backward propagation)\n",
    "* Inner-product layer\n",
    "* Activation layer(Sigmoid or Rectified)\n",
    "* Softmax layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7955ffd4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Using cached fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/n26141826/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/n26141826/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/n26141826/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Using cached matplotlib-3.10.7-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached numpy-2.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.60.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "Using cached kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "Using cached pillow-11.3.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: tqdm, pyparsing, pillow, numpy, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 numpy-2.3.3 pillow-11.3.0 pyparsing-3.2.5 tqdm-4.67.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib numpy tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c79c318f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3250,
     "status": "ok",
     "timestamp": 1760452572090,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "c79c318f",
    "outputId": "bee351b9-c4f4-4b49-86bc-976fc97d775f"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[32m      2\u001b[39m drive.mount(\u001b[33m'\u001b[39m\u001b[33m/content/drive\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1f1b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1760452572110,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "cfb1f1b4",
    "outputId": "d05bab6a-28b8-4b41-cacc-cbe00198a0da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: '/content/drive/MyDrive/AI_lab/Lab1 Material'\n",
      "/home/n26141826/Lab1 Material\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/AI_lab/Lab1\\ Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee38f895",
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1760452572126,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "ee38f895"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Callable, Iterable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ce009b2",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1760452572148,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "6ce009b2"
   },
   "outputs": [],
   "source": [
    "class Parameter:\n",
    "    def __init__(self, data: np.ndarray) -> None:\n",
    "        self.data = data\n",
    "        self.grad = None\n",
    "\n",
    "\n",
    "class Module:\n",
    "    def __call__(self, *args, **kwargs) -> np.ndarray:\n",
    "        return self.forward(*args, **kwargs)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        layers = '\\n'.join([f'  ({k}): {v}' for k, v in self.__dict__.items()])\n",
    "        return f'{self.__class__.__name__}(\\n{layers}\\n)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28a8912d",
   "metadata": {
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1760452572205,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "28a8912d"
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features) -> None:\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        init_factor = 0.01\n",
    "        self.W = Parameter(np.random.randn(in_features, out_features) * init_factor)\n",
    "        self.b = Parameter(np.zeros((1, out_features)))\n",
    "\n",
    "        # Cache for backward pass\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # y = x @ W + b\n",
    "        # x: (N, in_features), W: (in_features, out_features), b: (1, out_features)\n",
    "        self.x = x\n",
    "        return x @ self.W.data + self.b.data\n",
    "\n",
    "    def backward(self, dy):\n",
    "        # dy: (N, out_features)\n",
    "        # dW = x^T @ dy, db = sum(dy), dx = dy @ W^T\n",
    "        dW = self.x.T @ dy                                  # (in_features, out_features)\n",
    "        db = np.sum(dy, axis=0, keepdims=True)              # (1, out_features)\n",
    "        dx = dy @ self.W.data.T                             # (N, in_features)\n",
    "\n",
    "        # 寫回參數的梯度（通常外面會有 zero_grad() 再累加或覆蓋）\n",
    "        self.W.grad = dW\n",
    "        self.b.grad = db\n",
    "        return dx\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.W, self.b\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}(in_features={self.in_features}, out_features={self.out_features})'\n",
    "\n",
    "\n",
    "class ReLU(Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.x = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # y = max(0, x)\n",
    "        self.x = x\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def backward(self, dy):\n",
    "        # dy ⊙ 1_{x > 0}\n",
    "        mask = (self.x > 0).astype(dy.dtype)\n",
    "        return dy * mask\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}()'\n",
    "\n",
    "\n",
    "class Sigmoid(Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # y = 1 / (1 + exp(-x))\n",
    "        # 儲存 y 以便 backward 使用 y*(1-y)\n",
    "        y = 1.0 / (1.0 + np.exp(-x))\n",
    "        self.y = y\n",
    "        return y\n",
    "\n",
    "    def backward(self, dy):\n",
    "        # dy ⊙ y(1 - y)\n",
    "        return dy * (self.y * (1.0 - self.y))\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}()'\n",
    "\n",
    "\n",
    "class Softmax(Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.y = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 數值穩定 softmax\n",
    "        # x: (N, C)\n",
    "        x_shift = x - np.max(x, axis=1, keepdims=True)\n",
    "        exps = np.exp(x_shift)\n",
    "        y = exps / np.sum(exps, axis=1, keepdims=True)\n",
    "        self.y = y\n",
    "        return y\n",
    "\n",
    "    def backward(self, dy):\n",
    "        # 通常與 Cross-Entropy 合併成簡化梯度 (y - one_hot)\n",
    "        # 這裡維持講義設定：在 CE Loss 內完成簡化，因此此處直接回傳 dy\n",
    "        return dy\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f'{self.__class__.__name__}()'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60da9b4f",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1760452572215,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "60da9b4f"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLP(Module):\n",
    "    def __init__(self) -> None:\n",
    "        # 保持原模板的 __init__ 介面（不帶參數）\n",
    "        self.fc1 = Linear(28*28, 256)\n",
    "        self.act1 = ReLU()\n",
    "        self.fc2 = Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (N, 784) with values in [0,1]\n",
    "        z1 = self.fc1(x)\n",
    "        a1 = self.act1(z1)\n",
    "        z2 = self.fc2(a1)  # logits\n",
    "        return z2\n",
    "\n",
    "    def backward(self, dy):\n",
    "        # dy: gradient w.r.t logits\n",
    "        dz2 = self.fc2.backward(dy)\n",
    "        dz1 = self.act1.backward(dz2)\n",
    "        dx  = self.fc1.backward(dz1)\n",
    "        return dx\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.fc1.parameters() + self.fc2.parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1896d12f",
   "metadata": {
    "id": "1896d12f"
   },
   "source": [
    "## 2. Implement training and testing process\n",
    "* included cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd582fd",
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1760452572244,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "0fd582fd"
   },
   "outputs": [],
   "source": [
    "class MNIST:\n",
    "    # root請根據你的檔案位置更改\n",
    "    def __init__(self, root='../data', train=True, transform: Callable = None) -> None:\n",
    "        path = os.path.join(root, 'mnist_train.csv' if train else 'mnist_test.csv')\n",
    "        self.data = np.loadtxt(path, delimiter=',')\n",
    "        self.transform = transform\n",
    "        self.image_size = 28\n",
    "        self.num_classes = 10\n",
    "        self.classes = np.arange(self.num_classes)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = (self.data[idx, 0] == self.classes).astype(\n",
    "            np.float32\n",
    "        )  # one-hot encoding\n",
    "        image = (\n",
    "            self.data[idx, 1:]\n",
    "            .reshape(self.image_size * self.image_size)\n",
    "            .astype(np.float32)\n",
    "        )\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "class Subset:\n",
    "    def __init__(self, dataset, indices: Iterable) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.indices[idx]]\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size=1) -> None:\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.indices = np.arange(len(dataset))\n",
    "\n",
    "    def __len__(self):\n",
    "        return (len(self.dataset) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        for start_idx in range(0, len(self.dataset), self.batch_size):\n",
    "            end_idx = min(start_idx + self.batch_size, len(self.dataset))\n",
    "            batch_indices = self.indices[start_idx:end_idx]\n",
    "\n",
    "            batch_images = []\n",
    "            batch_labels = []\n",
    "\n",
    "            for idx in batch_indices:\n",
    "                image, label = self.dataset[idx]\n",
    "                batch_images.append(image)\n",
    "                batch_labels.append(label)\n",
    "\n",
    "            yield np.array(batch_images), np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f743cb90",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1760452572268,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "f743cb90"
   },
   "outputs": [],
   "source": [
    "# Separate train_imgs, train_labels into training and validation\n",
    "# root請根據你的檔案位置更改\n",
    "def load_mnist_data(\n",
    "    root=\".\", batch_size=1, split_ratio=0.1, transform=None\n",
    ") -> tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    def _split_dataset(dataset, split_ratio):\n",
    "        # 學生實作部分：split dataset into training and validation sets\n",
    "        # hint: return Subset(dataset, train_indices), Subset(dataset, valid_indices)\n",
    "        n = len(dataset)\n",
    "        indices = np.random.permutation(n)\n",
    "        n_valid = int(n * split_ratio)\n",
    "        valid_indices = indices[:n_valid]\n",
    "        train_indices = indices[n_valid:]\n",
    "        return Subset(dataset, train_indices), Subset(dataset, valid_indices)\n",
    "\n",
    "\n",
    "\n",
    "    trainset = MNIST(root=root, train=True, transform=transform)\n",
    "    testset = MNIST(root=root, train=False, transform=transform)\n",
    "    trainset, validset = _split_dataset(trainset, split_ratio=split_ratio)\n",
    "    trainldr = DataLoader(trainset, batch_size=batch_size)\n",
    "    validldr = DataLoader(validset, batch_size=batch_size)\n",
    "    testldr = DataLoader(testset, batch_size=batch_size)\n",
    "    return trainldr, validldr, testldr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fcfe45c",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1760452572286,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "2fcfe45c"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CrossEntropyLoss(Module):\n",
    "    def __init__(self, epsilon=1e-15) -> None:\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon  # small value to avoid log(0)\n",
    "        self.y_pred = None\n",
    "        self.y_true = None\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        self.y_pred = np.clip(y_pred, self.epsilon, 1 - self.epsilon)\n",
    "        self.y_true = y_true\n",
    "        batch_size = y_true.shape[0]\n",
    "        loss = -np.sum(y_true * np.log(self.y_pred)) / batch_size\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        batch_size = self.y_true.shape[0]\n",
    "        grad = (self.y_pred - self.y_true) / batch_size\n",
    "        return grad\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"{self.__class__.__name__}()\"\n",
    "\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, params: Iterable, lr: float = 1e-3) -> None:\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.data -= self.lr * param.grad\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            if param.grad is not None:\n",
    "                param.grad.fill(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "defbfc47",
   "metadata": {
    "executionInfo": {
     "elapsed": 99,
     "status": "ok",
     "timestamp": 1760453057221,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "defbfc47"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model: Module, trainldr: Iterable, criterion, optimizer) -> tuple[float, float]:\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    total_loss = 0.0\n",
    "    for x, y in tqdm(trainldr):\n",
    "        # 1) forward\n",
    "        logits = model(x)\n",
    "        # 2) loss (one-hot labels)\n",
    "        num_classes = 10\n",
    "        # y_onehot = np.eye(num_classes, dtype=np.float32)[y]\n",
    "        if y.ndim == 2 and y.shape[1] == num_classes:\n",
    "            # 已是 one-hot\n",
    "            y_onehot = y.astype(np.float32)\n",
    "            y_idx = np.argmax(y, axis=1)\n",
    "        else:\n",
    "            # 整數類別\n",
    "            y_idx = y.astype(np.int64).reshape(-1)\n",
    "            y_onehot = np.eye(num_classes, dtype=np.float32)[y_idx]\n",
    "        loss = criterion.forward(logits, y_onehot)\n",
    "\n",
    "        # 3) accuracy\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        # The y here is one-hot, convert it back to integer class indices for comparison\n",
    "        y_idx = np.argmax(y_onehot, axis=1)\n",
    "        correct += int((pred == y_idx).sum())\n",
    "        bs = x.shape[0]\n",
    "        total += bs\n",
    "        total_loss += loss * bs\n",
    "        # 4) backward\n",
    "        dlogits = criterion.backward()\n",
    "        model.backward(dlogits)\n",
    "        # 5) update\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model: Module, dataldr: Iterable) -> tuple[float, float]:\n",
    "    criterion = CrossEntropyLoss()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    total_loss = 0.0\n",
    "    for x, y in tqdm(dataldr):\n",
    "        logits = model(x)\n",
    "        num_classes = 10\n",
    "        # Ensure y is one-hot encoded for loss calculation and correct for accuracy\n",
    "        if y.ndim == 2 and y.shape[1] == num_classes:\n",
    "            # Already one-hot\n",
    "            y_onehot = y.astype(np.float32)\n",
    "            y_idx = np.argmax(y, axis=1)\n",
    "        else:\n",
    "            # Integer classes\n",
    "            y_idx = y.astype(np.int64).reshape(-1)\n",
    "            y_onehot = np.eye(num_classes, dtype=np.float32)[y_idx]\n",
    "\n",
    "        loss = criterion.forward(logits, y_onehot)\n",
    "        pred = np.argmax(logits, axis=1)\n",
    "        correct += int((pred == y_idx).sum()) # Compare prediction with integer class index\n",
    "        bs = x.shape[0]\n",
    "        total += bs\n",
    "        total_loss += loss * bs\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model: MLP, trainldr: Iterable, validldr: Iterable, epochs=10, lr=1e-3):\n",
    "    criterion = CrossEntropyLoss()\n",
    "    # 這邊提供SGD作為optimizer，同學也可以根據自己人需求更換其他optimizer\n",
    "    optimizer = SGD(model.parameters(), lr=lr)\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    valid_loss = []\n",
    "    valid_acc = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        loss, acc = train_one_epoch(model, trainldr, criterion, optimizer)\n",
    "        train_loss.append(loss)\n",
    "        train_acc.append(acc)\n",
    "        print(f'epoch {epoch:d}: train_loss = {loss}, train_acc = {acc}')\n",
    "\n",
    "        loss, acc = evaluate(model, validldr)\n",
    "        valid_loss.append(loss)\n",
    "        valid_acc.append(acc)\n",
    "        print(f'epoch {epoch:d}: valid_loss = {loss}, valid_acc = {acc}\\n')\n",
    "\n",
    "    return train_loss, train_acc, valid_loss, valid_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72aea9c",
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1760453105908,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "c72aea9c"
   },
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    \"\"\"map pixels information from range(0, 255) to range(0.01, 1)\"\"\"\n",
    "    x = np.asarray(x, dtype=np.float32) / 255.0\n",
    "    return np.asarray(x) * 0.99 + 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e2d100",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1e2d100",
    "outputId": "4bf6c46b-cf5d-4e3b-ccd9-29f8eff99c72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set: 54000 images\n",
      "validation set: 6000 images\n",
      "test set: 10000 images\n",
      "x shape: (1, 784)\n",
      "y shape: (1, 10)\n"
     ]
    }
   ],
   "source": [
    "# \"../data\"請根據你的檔案位置更改\n",
    "trainldr, validldr, testldr = load_mnist_data(\n",
    "    \".\", batch_size=1, transform=transform\n",
    ")\n",
    "print(f\"train set: {len(trainldr)} images\")\n",
    "print(f\"validation set: {len(validldr)} images\")\n",
    "print(f\"test set: {len(testldr)} images\")\n",
    "for x, y in trainldr:\n",
    "    print(f\"x shape: {x.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "baae834e",
   "metadata": {
    "executionInfo": {
     "elapsed": 68,
     "status": "aborted",
     "timestamp": 1760452578541,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "baae834e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run #1: epochs=10, lr=0.1 ===\n",
      "MLP(\n",
      "  (fc1): Linear(in_features=784, out_features=256)\n",
      "  (act1): ReLU()\n",
      "  (fc2): Linear(in_features=256, out_features=10)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|███▊                                                               | 3093/54000 [00:02<00:44, 1149.68it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(net)\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# 訓練\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m train_loss, train_acc, valid_loss, valid_acc = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainldr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidldr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mepochs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# 測試集評估\u001b[39;00m\n\u001b[32m     25\u001b[39m test_loss, test_acc = evaluate(net, testldr)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 83\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, trainldr, validldr, epochs, lr)\u001b[39m\n\u001b[32m     80\u001b[39m valid_acc = []\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m83\u001b[39m     loss, acc = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainldr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     84\u001b[39m     train_loss.append(loss)\n\u001b[32m     85\u001b[39m     train_acc.append(acc)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, trainldr, criterion, optimizer)\u001b[39m\n\u001b[32m     31\u001b[39m     model.backward(dlogits)\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# 5) update\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     optimizer.zero_grad()\n\u001b[32m     36\u001b[39m avg_loss = total_loss / total\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 29\u001b[39m, in \u001b[36mSGD.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28mself\u001b[39m.params = params\n\u001b[32m     27\u001b[39m     \u001b[38;5;28mself\u001b[39m.lr = lr\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.params:\n\u001b[32m     31\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m param.grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# 超參數實驗清單（你可自由增減）\n",
    "configs = [\n",
    "    {\"epochs\": 10, \"lr\": 0.10},\n",
    "    {\"epochs\": 20, \"lr\": 0.05},\n",
    "    {\"epochs\": 30, \"lr\": 0.01},\n",
    "]\n",
    "\n",
    "results = []  # 用來存每一組實驗的歷史與測試分數\n",
    "\n",
    "for i, cfg in enumerate(configs, start=1):\n",
    "    print(f\"\\n=== Run #{i}: epochs={cfg['epochs']}, lr={cfg['lr']} ===\")\n",
    "\n",
    "    # 每組實驗都重新建模，避免彼此影響\n",
    "    net = MLP()\n",
    "    print(net)\n",
    "\n",
    "    # 訓練\n",
    "    train_loss, train_acc, valid_loss, valid_acc = train(\n",
    "        net, trainldr, validldr, epochs=cfg[\"epochs\"], lr=cfg[\"lr\"]\n",
    "    )\n",
    "\n",
    "    # 測試集評估\n",
    "    test_loss, test_acc = evaluate(net, testldr)\n",
    "    print(f\"[Run #{i}] test_loss = {test_loss:.4f}, test_acc = {test_acc:.4f}\")\n",
    "\n",
    "    # 保存結果\n",
    "    results.append({\n",
    "        \"config\": cfg,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"valid_loss\": valid_loss,\n",
    "        \"valid_acc\": valid_acc,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_acc\": test_acc,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e0b93b",
   "metadata": {
    "id": "24e0b93b"
   },
   "source": [
    "## 3. Plot loss & accuracy curves(both Training and Validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85d6f3f",
   "metadata": {
    "executionInfo": {
     "elapsed": 9736,
     "status": "aborted",
     "timestamp": 1760452578543,
     "user": {
      "displayName": "marson Huang",
      "userId": "10482768600697558320"
     },
     "user_tz": -480
    },
    "id": "a85d6f3f"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation loss and accuracy curves\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(train_loss)+1), train_loss, label=\"train loss\")\n",
    "plt.plot(range(1, len(valid_loss)+1), valid_loss, label=\"valid loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(f\"Loss (epochs={cfg['epochs']}, lr={cfg['lr']})\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 總結列印（可選）\n",
    "print(\"\\n=== Summary ===\")\n",
    "for i, r in enumerate(results, start=1):\n",
    "    cfg = r[\"config\"]\n",
    "    print(f\"Run #{i} | epochs={cfg['epochs']}, lr={cfg['lr']} | \"\n",
    "          f\"test_loss={r['test_loss']:.4f}, test_acc={r['test_acc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ea4fa2-1efe-43ab-bfe4-bc6e0809f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Multicore trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb1905-1954-418b-ab76-8383aa8600d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU cores: 30\n",
      "Submitting experiments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 422/422 [03:12<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: train_loss = 2.057968866476436, train_acc = 0.6243888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 422/422 [03:13<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: train_loss = 1.3869228233476565, train_acc = 0.7875925925925926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|████▊                                                                      | 3/47 [00:00<00:11,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 422/422 [03:16<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: train_loss = 1.3019118059854853, train_acc = 0.8354074074074074"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|██████████████▎                                                            | 9/47 [00:02<00:11,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: valid_loss = 1.3795617682422396, valid_acc = 0.7416666666666667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: valid_loss = 1.1425121916835324, valid_acc = 0.8758333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                         | 3/422 [00:01<03:07,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: valid_loss = 1.0202865625671191, valid_acc = 0.902\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 422/422 [03:14<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss = 1.187679086870962, train_acc = 0.7789444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 422/422 [03:13<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss = 1.1537217404258029, train_acc = 0.8927962962962963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▏                                                                       | 2/47 [00:00<00:11,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 422/422 [03:14<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train_loss = 0.9412260803849741, train_acc = 0.9154074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: valid_loss = 1.1235517826116979, valid_acc = 0.811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████████████████████████████▌                    | 34/47 [00:09<00:03,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.54it/s]\n",
      "  0%|▏                                                                         | 1/422 [00:00<02:37,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: valid_loss = 0.9830813409429547, valid_acc = 0.9035\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: valid_loss = 0.7622338298418143, valid_acc = 0.9271666666666667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 422/422 [03:13<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train_loss = 0.9932897266738824, train_acc = 0.910537037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 422/422 [03:14<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train_loss = 1.1548291990310815, train_acc = 0.8345185185185185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 422/422 [03:15<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: train_loss = 0.7207506287925451, train_acc = 0.9346851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.59it/s]\n",
      " 91%|███████████████████████████████████████████████████████████████▏     | 43/47 [00:12<00:01,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: valid_loss = 0.8493452476327746, valid_acc = 0.9166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████▋                             | 27/47 [00:07<00:05,  3.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.43it/s]\n",
      " 66%|█████████████████████████████████████████████▌                       | 31/47 [00:08<00:04,  3.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: valid_loss = 1.1242479839769643, valid_acc = 0.8485\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: valid_loss = 0.6298396093503534, valid_acc = 0.9408333333333333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:15<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: train_loss = 0.8598643413443288, train_acc = 0.9229814814814815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:15<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: train_loss = 1.1866756806880998, train_acc = 0.8623518518518518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:13<00:00,  2.18it/s]\n",
      " 30%|████████████████████▌                                                | 14/47 [00:04<00:09,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: train_loss = 0.590518400576159, train_acc = 0.9457407407407408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|████████████████▏                                                    | 11/47 [00:03<00:09,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: valid_loss = 0.7621443643670064, valid_acc = 0.926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████████████████████████████▍                    | 33/47 [00:09<00:03,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: valid_loss = 1.1345754269162445, valid_acc = 0.8723333333333333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: valid_loss = 0.5392359118846489, valid_acc = 0.9496666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▍                                                                   | 9/422 [00:04<03:10,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:14<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: train_loss = 1.197374516263244, train_acc = 0.8761851851851852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:16<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: train_loss = 0.761539326634396, train_acc = 0.932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:14<00:00,  2.17it/s]\n",
      " 19%|█████████████▍                                                        | 9/47 [00:02<00:10,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: train_loss = 0.5036595044198806, train_acc = 0.9530925925925926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: valid_loss = 1.1430675431594364, valid_acc = 0.8803333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|████████████████████████████████████████████████████▊                | 36/47 [00:10<00:03,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: valid_loss = 0.6807499579119987, valid_acc = 0.9341666666666667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4: valid_loss = 0.47348217051364455, valid_acc = 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▏                                                                   | 7/422 [00:03<03:09,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:12<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: train_loss = 0.6801226555891201, train_acc = 0.9385370370370371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:13<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: train_loss = 1.186259201221066, train_acc = 0.8842962962962962"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████████████████████████████████████████████████████████████▋ | 414/422 [03:09<00:03,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:13<00:00,  2.18it/s]\n",
      " 32%|██████████████████████                                               | 15/47 [00:04<00:08,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: train_loss = 0.42924756522688423, train_acc = 0.9594074074074074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: valid_loss = 0.6335216890304054, valid_acc = 0.9418333333333333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: valid_loss = 1.100260490072499, valid_acc = 0.8881666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                    | 1/422 [00:00<02:58,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: valid_loss = 0.4142997058818422, valid_acc = 0.9595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|█▎                                                                   | 8/422 [00:03<03:08,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:13<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: train_loss = 0.6116108129390601, train_acc = 0.944037037037037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:13<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: train_loss = 1.1732237468166198, train_acc = 0.8907777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:13<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: train_loss = 0.37979010894588616, train_acc = 0.9642407407407407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: valid_loss = 0.5886555627877251, valid_acc = 0.9468333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████▍                 | 35/47 [00:09<00:03,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: valid_loss = 1.0629461953186992, valid_acc = 0.8948333333333334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6: valid_loss = 0.3846531530546534, valid_acc = 0.963\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:15<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: train_loss = 0.5633554200642504, train_acc = 0.9484814814814815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:15<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: train_loss = 1.1501417276087498, train_acc = 0.8956296296296297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 422/422 [03:13<00:00,  2.18it/s]\n",
      "  9%|█████▉                                                                | 4/47 [00:01<00:12,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: train_loss = 0.3377772758086245, train_acc = 0.9683703703703703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: valid_loss = 1.0373828729911854, valid_acc = 0.8981666666666667\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:14<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: valid_loss = 0.5385893106022605, valid_acc = 0.9495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                                                    | 1/422 [00:00<03:17,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 47/47 [00:13<00:00,  3.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7: valid_loss = 0.3634122876074879, valid_acc = 0.9658333333333333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|███████████████████████████████▎                                   | 197/422 [01:29<01:39,  2.27it/s]"
     ]
    }
   ],
   "source": [
    "# --------- 頂層 worker 函式（很重要：不要寫在函式內層或 lambda）---------\n",
    "def run_experiment(cfg, data_root=\".\", batch_size=128, seed=42):\n",
    "    \"\"\"\n",
    "    在獨立進程中執行一組 (epochs, lr) 訓練：\n",
    "      1) 重新建立 dataloader（避免跨進程 pickle 問題）\n",
    "      2) 建立新模型訓練\n",
    "      3) 在 test set 上評估\n",
    "      4) 回傳訓練歷史與測試分數\n",
    "    \"\"\"\n",
    "    # 進程內設種子（數值版）\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # 重新建 dataloader（依你的資料位置調整 data_root / transform）\n",
    "    trainldr, validldr, testldr = load_mnist_data(\n",
    "        data_root, batch_size=batch_size, transform=transform\n",
    "    )\n",
    "\n",
    "    # 建立模型並訓練\n",
    "    net = MLP()\n",
    "    train_loss, train_acc, valid_loss, valid_acc = train(\n",
    "        net, trainldr, validldr, epochs=cfg[\"epochs\"], lr=cfg[\"lr\"]\n",
    "    )\n",
    "\n",
    "    # 測試集評估\n",
    "    test_loss, test_acc = evaluate(net, testldr)\n",
    "\n",
    "    # 轉成基本型態，避免跨進程傳 cupy/tensor 等特殊型別\n",
    "    return {\n",
    "        \"config\": dict(cfg),\n",
    "        \"train_loss\": list(map(float, train_loss)),\n",
    "        \"train_acc\": list(map(float, train_acc)),\n",
    "        \"valid_loss\": list(map(float, valid_loss)),\n",
    "        \"valid_acc\": list(map(float, valid_acc)),\n",
    "        \"test_loss\": float(test_loss),\n",
    "        \"test_acc\": float(test_acc),\n",
    "    }\n",
    "\n",
    "# --------- 主程式：開多核心跑多組超參數 ---------\n",
    "def main_multicore():\n",
    "    # 你要掃的 (epochs, lr) 清單（可自行增減）\n",
    "    configs = [\n",
    "        {\"epochs\": 10, \"lr\": 0.10},\n",
    "        {\"epochs\": 20, \"lr\": 0.05},\n",
    "        {\"epochs\": 30, \"lr\": 0.01},\n",
    "    ]\n",
    "\n",
    "    # 建議加大 batch_size，GPU 沒開也能讓曲線穩定許多\n",
    "    batch_size = 128\n",
    "    data_root = \".\"\n",
    "\n",
    "    # 工作者數量：別把整機用滿，通常留 1 核給系統\n",
    "    max_workers = max(1, (os.cpu_count()) - 2)\n",
    "\n",
    "    print(f\"Using CPU cores: {max_workers}\")\n",
    "    print(\"Submitting experiments...\")\n",
    "    ctx = mp.get_context(\"fork\")\n",
    "    results = []\n",
    "    with ProcessPoolExecutor(max_workers=max_workers, mp_context=ctx) as ex:\n",
    "        futures = [ex.submit(run_experiment, cfg, data_root, batch_size, 42)\n",
    "                   for cfg in configs]\n",
    "        for fut in as_completed(futures):\n",
    "            res = fut.result()\n",
    "            cfg = res[\"config\"]\n",
    "            print(f\"Finished: epochs={cfg['epochs']}, lr={cfg['lr']}, \"\n",
    "                  f\"test_loss={res['test_loss']:.4f}, test_acc={res['test_acc']:.4f}\")\n",
    "            results.append(res)\n",
    "    # 繪圖（含 plt.show()）\n",
    "    for res in results:\n",
    "        cfg = res[\"config\"]\n",
    "        tl, vl = res[\"train_loss\"], res[\"valid_loss\"]\n",
    "        ta, va = res[\"train_acc\"], res[\"valid_acc\"]\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, len(tl)+1), tl, label=\"train loss\")\n",
    "        plt.plot(range(1, len(vl)+1), vl, label=\"valid loss\")\n",
    "        plt.xlabel(\"epoch\"); plt.ylabel(\"loss\")\n",
    "        plt.title(f\"Loss (epochs={cfg['epochs']}, lr={cfg['lr']})\")\n",
    "        plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(range(1, len(ta)+1), ta, label=\"train acc\")\n",
    "        plt.plot(range(1, len(va)+1), va, label=\"valid acc\")\n",
    "        plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\")\n",
    "        plt.title(f\"Accuracy (epochs={cfg['epochs']}, lr={cfg['lr']})\")\n",
    "        plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()\n",
    "    return results\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = main_multicore()\n",
    "    \n",
    "    # ---- 總結（每個 run 一列）----\n",
    "    summary_csv = \"results_summary.csv\"\n",
    "    with open(summary_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"run_id\", \"epochs_cfg\", \"lr_cfg\",\n",
    "            \"final_train_loss\", \"final_valid_loss\",\n",
    "            \"final_train_acc\", \"final_valid_acc\",\n",
    "            \"test_loss\", \"test_acc\"\n",
    "        ])\n",
    "        for run_id, res in enumerate(results, start=1):\n",
    "            cfg = res[\"config\"]\n",
    "            tl, vl = res[\"train_loss\"], res[\"valid_loss\"]\n",
    "            ta, va = res[\"train_acc\"], res[\"valid_acc\"]\n",
    "            writer.writerow([\n",
    "                run_id, cfg[\"epochs\"], cfg[\"lr\"],\n",
    "                tl[-1], vl[-1], ta[-1], va[-1],\n",
    "                res[\"test_loss\"], res[\"test_acc\"]\n",
    "            ])\n",
    "    \n",
    "    print(f\"[CSV] summary written to: {summary_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905041b1-7c32-4ff7-b8bf-bed9f3532449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.18 (lab)",
   "language": "python",
   "name": "lab-3127"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
